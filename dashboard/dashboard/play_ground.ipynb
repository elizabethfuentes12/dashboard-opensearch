{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "file = \"templat.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_value = {\n",
    "    \"REGION_NAME\": \"es-west-1\",\n",
    "    \"BUCKET_NAME\": \"nombre\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_valores(ruta_archivo, reemplazos):\n",
    "    \"\"\"\n",
    "    Función que lee un archivo de texto, reemplaza valores según un diccionario\n",
    "    de reemplazos y devuelve el contenido actualizado como un string.\n",
    "\n",
    "    Args:\n",
    "        ruta_archivo (str): La ruta del archivo de texto.\n",
    "        reemplazos (dict): Un diccionario donde las claves son los valores a\n",
    "                           reemplazar y los valores son los nuevos valores.\n",
    "\n",
    "    Returns:\n",
    "        str: El contenido del archivo con los valores reemplazados.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ruta_archivo, 'r') as archivo:\n",
    "            contenido = archivo.read()\n",
    "            \n",
    "            for clave, valor in reemplazos.items():\n",
    "                contenido = contenido.replace(clave, valor)\n",
    "            \n",
    "            return contenido\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {ruta_archivo} no existe.\")\n",
    "        return None\n",
    "    except IOError:\n",
    "        print(f\"Error al leer el archivo {ruta_archivo}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenido = reemplazar_valores(file, replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: \"2\"\n",
      "dynamodb-pipeline:\n",
      "  source:\n",
      "    dynamodb:\n",
      "      acknowledgments: true\n",
      "      tables:\n",
      "        # REQUIRED: Supply the DynamoDB table ARN and whether export or stream processing is needed, or both\n",
      "        - table_arn: \"DYNAMODB_TABLE_NAME\"\n",
      "          # Remove the stream block if only export is needed\n",
      "          stream:\n",
      "            start_position: \"LATEST\"\n",
      "          # Remove the export block if only stream is needed\n",
      "          export:\n",
      "            # REQUIRED for export: Specify the name of an existing S3 bucket for DynamoDB to write export data files to\n",
      "            s3_bucket: \"nombre\"\n",
      "            # Specify the region of the S3 bucket\n",
      "            s3_region: \"es-west-1\"\n",
      "            # Optionally set the name of a prefix that DynamoDB export data files are written to in the bucket.\n",
      "            s3_prefix: \"ddb-to-opensearch-export/\"\n",
      "      aws:\n",
      "        # REQUIRED: Provide the role to assume that has the necessary permissions to DynamoDB, OpenSearch, and S3.\n",
      "        sts_role_arn: \"STS_ROLE_ARN\"\n",
      "        # Provide the region to use for aws credentials\n",
      "        region: \"es-west-1\"\n",
      "  sink:\n",
      "    - opensearch:\n",
      "        # REQUIRED: Provide an AWS OpenSearch endpoint\n",
      "        hosts:\n",
      "          [\n",
      "            \"OpenSearch_DOMAIN\"\n",
      "          ]\n",
      "        index: \"table-index\"\n",
      "        index_type: custom\n",
      "        document_id: \"${getMetadata(\\\"primary_key\\\")}\"\n",
      "        action: \"${getMetadata(\\\"opensearch_action\\\")}\"\n",
      "        document_version: \"${getMetadata(\\\"document_version\\\")}\"\n",
      "        document_version_type: \"external\"\n",
      "        aws:\n",
      "          # REQUIRED: Provide a Role ARN with access to the domain. This role should have a trust relationship with osis-pipelines.amazonaws.com\n",
      "          sts_role_arn: \"STS_ROLE_ARN\"\n",
      "          # Provide the region of the domain.\n",
      "          region: \"es-west-1\"\n",
      "          # Enable the 'serverless' flag if the sink is an Amazon OpenSearch Serverless collection\n",
      "          # serverless: true\n",
      "          # serverless_options:\n",
      "          # Specify a name here to create or update network policy for the serverless collection\n",
      "          # network_policy_name: \"network-policy-name\"\n",
      "          # Enable the S3 DLQ to capture any failed requests in an S3 bucket. This is recommended as a best practice for all pipelines.\n",
      "          # dlq:\n",
      "          # s3:\n",
      "          # Provide an S3 bucket\n",
      "          # bucket: \"your-dlq-bucket-name\"\n",
      "          # Provide a key path prefix for the failed requests\n",
      "          # key_path_prefix: \"dynamodb-pipeline/dlq\"\n",
      "          # Provide the region of the bucket.\n",
      "          # region: \"us-east-1\"\n",
      "          # Provide a Role ARN with access to the bucket. This role should have a trust relationship with osis-pipelines.amazonaws.com\n",
      "          # sts_role_arn: \"arn:aws:iam::123456789012:role/Example-Role\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
